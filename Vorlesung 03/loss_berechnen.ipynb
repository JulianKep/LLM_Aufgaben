{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a31b0e-574a-4d05-8fc5-20f1e22181b8",
   "metadata": {},
   "source": [
    "# Loss Berechnen\n",
    "\n",
    "In diesem Notebook bauen wir auf unserer statistischen Generierung auf, die wir uns in Vorlesung zwei erarbeitet haben.\n",
    "Nun wollen wir aber einen Schritt weiter gehen - wir wollen uns objektiv berechnen, wie gut unserer Vorhersage tatsächlich ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612fae6b-5c3a-4214-8d6e-d542eed963c5",
   "metadata": {},
   "source": [
    "Schritt 1: Wir nehmen den wichtigsten Teil des Codes aus der letzten Vorlesung.\n",
    "\n",
    "Wir brauchen:\n",
    "- Unsere Liste mit unseren Originaldaten (Trainingsdaten)\n",
    "- Unsere Liste mit unseren Random generierten Namen (Baseline)\n",
    "- Unsere Liste mit den statistisch generierten Namen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577d6285-8690-4e76-ab35-9c204cfc286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60cf25dc-d547-4c7f-95ca-a823b7aaecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "lines = open(\"data/vornamenstatistik_24.csv\", \"r\", encoding=\"utf-8\").read().splitlines()\n",
    "names = list(set([n.split(\",\")[1] for n in lines][1:])) # Liste mit Originaldaten\n",
    "\n",
    "sorted_names = sorted(names, key=lambda x: len(x))\n",
    "count_chars = {}\n",
    "for w in sorted_names:\n",
    "    chars = [\"<s>\"] + list(w) + [\"<e>\"]\n",
    "    for c1 in chars:\n",
    "        count_chars[c1.lower()] = count_chars.get(c1.lower(), 0) + 1\n",
    "all_chars = list(count_chars.keys())\n",
    "sorted_chars = sorted(count_chars.items(), key=lambda x: x[1])\n",
    "frequent_chars = [i for i in all_chars if count_chars[i] >= 10]\n",
    "\n",
    "N_2 = torch.zeros((len(frequent_chars),len(frequent_chars)), dtype=torch.int32)\n",
    "\n",
    "for w in sorted_names:\n",
    "    chars = [\"<S>\"] + list(w) + [\"<E>\"]\n",
    "    for c1, c2 in zip(chars, chars[1:]):\n",
    "        if c1.lower() in frequent_chars and c2.lower() in frequent_chars:\n",
    "            id_x = frequent_chars.index(c1.lower())\n",
    "            id_y = frequent_chars.index(c2.lower())\n",
    "        # Statt in unserem Dictionary hochzuzählen, zählen wir jetzt an der Matrixposition\n",
    "        N_2[id_x, id_y] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a8aae3-7174-4566-856d-54b4619e9015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yá',\n",
       " '<s>yeátmuéb<s>phsecy',\n",
       " 'cmbnwopnfsnevqq',\n",
       " 'kuná',\n",
       " 'kc',\n",
       " 'xgnxwreéaj--',\n",
       " 'bj<e>degpk',\n",
       " 'dtnl',\n",
       " 'áz<s>x',\n",
       " 'č<e>čéál<e>noeti<e>jd']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_names = [] # Liste mit Random Names als Baseline\n",
    "for i in range(10):\n",
    "    name = \"\"\n",
    "    rand_len = random.randint(2,17)\n",
    "    for i in range(rand_len):\n",
    "        buchstabe = random.choice(frequent_chars)\n",
    "        name += buchstabe\n",
    "    random_names.append(name)\n",
    "    \n",
    "random_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5756a6f0-0ea6-4ed1-b124-1e643fe09182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lkaninri',\n",
       " 'uakialavikonasasayualininannti',\n",
       " 'n',\n",
       " 'ma',\n",
       " 'a',\n",
       " 'iov',\n",
       " 'keharima',\n",
       " 'b',\n",
       " 'wia',\n",
       " 'sanel']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BT = torch.zeros(len(frequent_chars), len(frequent_chars))\n",
    "\n",
    "for n in names:\n",
    "    char = [\"<s>\"] + list(n) + [\"<e>\"]\n",
    "    for c1, c2 in zip(char, char[1:]): \n",
    "        if c1.lower() in frequent_chars and c2.lower() in frequent_chars:\n",
    "            id_x = frequent_chars.index(c1.lower())\n",
    "            id_y = frequent_chars.index(c2.lower())\n",
    "            BT[id_x, id_y] += 1\n",
    "\n",
    "g = torch.Generator().manual_seed(42)\n",
    "\n",
    "P = (BT).float() # Wir ersparen uns Zeit und Rechenleistung, in dem wir nicht jedes Mal die Float-konvertiereung machen müssen\n",
    "P = P / P.sum(1, keepdims=True)\n",
    "\n",
    "generierte_name = []  # Unsere Liste mit statistisch generierten Namen\n",
    "for i in range(10):\n",
    "    curr_char = \"<s>\"\n",
    "    name = \"\"\n",
    "    while curr_char != \"<e>\":\n",
    "        p = P[frequent_chars.index(curr_char)]\n",
    "        ind = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        char = frequent_chars[ind]\n",
    "        curr_char = char\n",
    "        name += curr_char\n",
    "    generierte_name.append(name[:-3])\n",
    "generierte_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292a95bf-8adc-43ac-8cad-a9bb62a3b0a3",
   "metadata": {},
   "source": [
    "Schritt 2: Wir wollen jetzt berechnen, wie gut oder schlecht unser Modell uns Namen generiert. \n",
    "Da wir nur die statistische Häufigkeit von Bigrams bisher hinzugezogen haben, arbeiten wir mit dieser jetzt auch weiter. \n",
    "\n",
    "Wir schauen uns zunächst an, wie wahrscheinlich die Bigramme unserer Originaldaten sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3820b75-5620-4862-8595-edbb42583aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>m: 0.11987809091806412\n",
      "ml: 0.0024906599428504705\n",
      "la: 0.1507052779197693\n",
      "ad: 0.02787456475198269\n",
      "de: 0.16033755242824554\n",
      "en: 0.13243408501148224\n",
      "no: 0.0649966150522232\n",
      "ov: 0.05088495463132858\n",
      "v<e>: 0.0625\n",
      "<s>m: 0.11987809091806412\n",
      "ma: 0.4146949052810669\n",
      "al: 0.07456445693969727\n",
      "lv: 0.014847810380160809\n",
      "vi: 0.3888888955116272\n",
      "in: 0.15510204434394836\n",
      "na: 0.1970209926366806\n",
      "a<e>: 0.28710800409317017\n",
      "<s>v: 0.02404334582388401\n",
      "vo: 0.0243055559694767\n",
      "ol: 0.10619468986988068\n",
      "lk: 0.011135857552289963\n",
      "ke: 0.10223641991615295\n",
      "er: 0.0790925845503807\n",
      "r<e>: 0.11347517371177673\n"
     ]
    }
   ],
   "source": [
    "for w in names[:3]:\n",
    "    chars = [\"<s>\"] + list(w) + [\"<e>\"]\n",
    "    for c1, c2 in zip(chars, chars[1:]):\n",
    "        id_x = frequent_chars.index(c1.lower())\n",
    "        id_y = frequent_chars.index(c2.lower())\n",
    "        prob = P[id_x, id_y]\n",
    "        print(f'{frequent_chars[id_x]}{frequent_chars[id_y]}: {prob}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e22a2d6-97ca-4d8d-91a0-b803e1a20c54",
   "metadata": {},
   "source": [
    "Wir sehen - einige Kombinationen sind sehr häufig, wie zum Beispiel \"ya\", währen andere sehr selten sind, wie zum Beispiel \"nz\".\n",
    "\n",
    "Um jetzt die Wahrscheinlichkeit eines Wortes zu berechnen, multipliziert man alle Einzelwahrscheinlichkeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcff4a03-6423-499e-ae23-ba29facd8ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mladenov: 5.505363092489501e-12\n",
      "Malvina: 1.877861848242901e-07\n",
      "Volker: 6.341166480794413e-10\n"
     ]
    }
   ],
   "source": [
    "for w in names[:3]:\n",
    "    likelihood = 1\n",
    "    chars = [\"<s>\"] + list(w) + [\"<e>\"]\n",
    "    for c1, c2 in zip(chars, chars[1:]):\n",
    "        id_x = frequent_chars.index(c1.lower())\n",
    "        id_y = frequent_chars.index(c2.lower())\n",
    "        prob = P[id_x, id_y]\n",
    "        likelihood *= prob\n",
    "    print(f'{w}: {likelihood}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d529c6e4-5061-40c7-9fb4-a8ea9aa27e68",
   "metadata": {},
   "source": [
    "Von den ersten Namen hat \"Amaya\" den statistisch höchsten Wert. Aber die Werte werden alle sehr klein. Deswegen nehmen wir statt dem ursprünglichen Wert den Logarithmus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6175ccb4-b348-4635-91b8-c34c0e5777a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mladenov: -25.925296783447266\n",
      "Malvina: -15.487961769104004\n",
      "Volker: -21.178787231445312\n"
     ]
    }
   ],
   "source": [
    "for w in names[:3]:\n",
    "    log_likelihood = 0.0\n",
    "    chars = [\"<s>\"] + list(w) + [\"<e>\"]\n",
    "    for c1, c2 in zip(chars, chars[1:]):\n",
    "        id_x = frequent_chars.index(c1.lower())\n",
    "        id_y = frequent_chars.index(c2.lower())\n",
    "        prob = P[id_x, id_y]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "    print(f'{w}: {log_likelihood}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5869d055-74de-48e2-922b-534cd22f5f54",
   "metadata": {},
   "source": [
    "Bei dieser Art von Berechnung ist der Wert besser, je näher er an der Null liegt. Leichter zu interpretieren wäre es, wenn wir daraus ein Minimierungsproblem machen könnten - also wenn kleine Werte => besser.\n",
    "Dafür nehmen wir einfach die negative log-likelihood.\n",
    "\n",
    "Eine letzte Modifikation bauen wir noch ein - statt die Werste einfach nur aufzusummieren und damit längere Namen zu benachteiligen, wollen wir den Mittelwert nehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb215792-22b2-49c1-9326-e03907e14485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4544275189861757\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "avg_log_likelihood = []\n",
    "for w in names:\n",
    "    log_likelihood = 0.0\n",
    "    num_bigrams = 0\n",
    "    chars = [\"<s>\"] + list(w) + [\"<e>\"]\n",
    "    for c1, c2 in zip(chars, chars[1:]):\n",
    "        if c1.lower() in frequent_chars and c2.lower() in frequent_chars:\n",
    "            num_bigrams += 1\n",
    "            id_x = frequent_chars.index(c1.lower())\n",
    "            id_y = frequent_chars.index(c2.lower())\n",
    "            prob = P[id_x, id_y]\n",
    "            logprob = torch.log(prob)\n",
    "            log_likelihood += logprob\n",
    "    avg_log_likelihood.append((-log_likelihood / num_bigrams).item())\n",
    "print(mean(avg_log_likelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2b651c-408c-4026-9302-1213a3b5d3c1",
   "metadata": {},
   "source": [
    "Jetzt haben wir uns unsere Baseline berechnet - In unseren originalen Namensdaten haben Namen im Schnitt eine Negative Log-Likelihood von 2.45. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1593be54-6065-4a22-b8b3-711a854f014f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.791491985321045\n"
     ]
    }
   ],
   "source": [
    "avg_log_likelihood_rand = []\n",
    "for w in random_names:\n",
    "    log_likelihood = 0.0\n",
    "    num_bigrams = 0\n",
    "    chars = [\"<s>\"] + list(w) + [\"<e>\"]\n",
    "    for c1, c2 in zip(chars, chars[1:]):\n",
    "        if c1.lower() in frequent_chars and c2.lower() in frequent_chars:\n",
    "            num_bigrams += 1\n",
    "            id_x = frequent_chars.index(c1.lower())\n",
    "            id_y = frequent_chars.index(c2.lower())\n",
    "            prob = P[id_x, id_y]\n",
    "            if prob == 0:\n",
    "                prob = torch.tensor(0.00001)  # Für eine Wahrscheinlichkeit von 0 ist der logarithmus unendlich; hier nutzen wir eine leichte Art das zu verhindern\n",
    "            logprob = torch.log(prob)\n",
    "            log_likelihood += logprob\n",
    "    avg_log_likelihood_rand.append((-log_likelihood / num_bigrams).item())\n",
    "print(mean(avg_log_likelihood_rand))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83e3771-909d-4b13-86a0-16aa0e422711",
   "metadata": {},
   "source": [
    "Wir sehen - random generierte Namen haben eine deutliche schlechtere mittlere Wahrscheinlichkeit.\n",
    "\n",
    "Aber wie sieht es jetzt mit unseren statistischn generierten Namen aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61924629-237e-4cc3-82c7-0e0de7eb49cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.337066102027893\n"
     ]
    }
   ],
   "source": [
    "avg_log_likelihood_gen = []\n",
    "for w in generierte_name:\n",
    "    log_likelihood = 0.0\n",
    "    num_bigrams = 0\n",
    "    chars = [\"<s>\"] + list(w) + [\"<e>\"]\n",
    "    for c1, c2 in zip(chars, chars[1:]):\n",
    "        if c1.lower() in frequent_chars and c2.lower() in frequent_chars:\n",
    "            num_bigrams += 1\n",
    "            id_x = frequent_chars.index(c1.lower())\n",
    "            id_y = frequent_chars.index(c2.lower())\n",
    "            prob = P[id_x, id_y]\n",
    "            if prob == 0:\n",
    "                prob = torch.tensor(0.00001)  # Für eine Wahrscheinlichkeit von 0 ist der logarithmus unendlich; hier nutzen wir eine leichte Art das zu verhindern\n",
    "            logprob = torch.log(prob)\n",
    "            log_likelihood += logprob\n",
    "    avg_log_likelihood_gen.append((-log_likelihood / num_bigrams).item())\n",
    "print(mean(avg_log_likelihood_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b8dc9f-7a02-48d6-9785-d43e703eb65d",
   "metadata": {},
   "source": [
    "Statistisch stehen unsere generierten Namen sogar leicht besser da als unsere echten Vornamen. Auf jeden Fall erwarten wir einen Wert, der grob im gleichen Rahmen liegt wie unsere Ausgangsdaten: Darauf haben wir ja unsere statistische Berechnung trainiert, das heißt wir können auch kein Ergebnis erwarten, dass besser ist als unsere Trainingsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a1549-df51-4a7e-830a-d31d2ba44fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
